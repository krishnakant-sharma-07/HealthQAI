{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDqUKPNmkNmX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ast  # To safely evaluate list-like strings\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/final_disease_dataset_complete.csv\")\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/final_disease_dataset_complete.csv')\n",
        "\n",
        "# Function to clean and extract symptom list\n",
        "def extract_symptoms(raw):\n",
        "    if pd.isna(raw):\n",
        "        return []\n",
        "    try:\n",
        "        # Remove everything from 'Detailed:' onward\n",
        "        cleaned = re.split(r'Detailed:', raw)[0].strip()\n",
        "        # Try to parse the list safely\n",
        "        symptoms_list = ast.literal_eval(cleaned)\n",
        "        if isinstance(symptoms_list, list):\n",
        "            return [s.strip().strip(\"'\").strip('\"') for s in symptoms_list]\n",
        "    except:\n",
        "        return []\n",
        "    return []\n",
        "\n",
        "# Apply to Symptoms column\n",
        "df['Symptoms'] = df['Symptoms'].apply(extract_symptoms)\n",
        "\n",
        "# Also create a readable string version for modeling or LLM\n",
        "df['SymptomsText'] = df['Symptoms'].apply(lambda x: ', '.join(x))\n",
        "\n",
        "# Preview result\n",
        "df[['Disease', 'SymptomsText']].head(10)\n"
      ],
      "metadata": {
        "id": "AnKv53HSkk4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "B6rOgkv4nrNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Use 'SymptomsText' and 'Disease' columns\n",
        "X = df['SymptomsText']\n",
        "y = df['Disease']\n",
        "\n",
        "# TF-IDF vectorization of symptoms text\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_vec = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "jwR-YxY8oXqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Train a Logistic Regression model"
      ],
      "metadata": {
        "id": "P2LS2bNcpFcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "hyLTOOj9orhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_disease(symptoms_input):\n",
        "    input_vec = vectorizer.transform([symptoms_input])\n",
        "    prediction = model.predict(input_vec)[0]\n",
        "\n",
        "    # Get more details from the dataset\n",
        "    details = df[df['Disease'] == prediction].iloc[0]\n",
        "    print(f\"üîç Predicted Disease: {prediction}\\n\")\n",
        "    print(f\"üß† Diagnosis: {details.get('Diagnosis', 'N/A')}\")\n",
        "    print(f\"üíä Treatment: {details.get('Treatment', 'N/A')}\")\n",
        "    print(f\"üõ°Ô∏è  Precautions: {details.get('Basic Precautions', 'N/A')}\")\n",
        "    # print(f\"‚ö†Ô∏è  When to See a Doctor: {details.get('When to See a Doctor', 'N/A')}\")\n",
        "\n",
        "# Test\n",
        "predict_disease(\"high fever, headache, body pain\")\n"
      ],
      "metadata": {
        "id": "OFOpzAUTpHFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NEW"
      ],
      "metadata": {
        "id": "xhsGmzylqz9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers sentence-transformers torch scikit-learn pandas numpy flask datasets accelerate\n",
        "!pip install peft bitsandbytes  # For fine-tuning"
      ],
      "metadata": {
        "id": "BVh8xDPPqwGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "\n",
        "# 1. Proper CSV Loading with Error Handling\n",
        "def load_medical_data(filepath):\n",
        "    try:\n",
        "        # First attempt with standard reading\n",
        "        df = pd.read_csv(filepath)\n",
        "    except pd.errors.ParserError:\n",
        "        # If error occurs, try reading with error handling\n",
        "        df = pd.read_csv(filepath, on_bad_lines='warn', engine='python')\n",
        "        print(\"Warning: Some rows had formatting issues and were skipped\")\n",
        "\n",
        "    # Alternative approach if still having issues\n",
        "    if len(df.columns) != 8:  # Adjust based on your expected column count\n",
        "        # Manually specify columns if headers are known\n",
        "        cols = ['Disease', 'Symptoms', 'Causes', 'Treatment',\n",
        "                'Basic Precautions', 'Additional Precautions',\n",
        "                'Diagnosis', 'When to See a Doctor']\n",
        "        df = pd.read_csv(filepath, names=cols, header=0, on_bad_lines='skip')\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load your dataset\n",
        "df = load_medical_data('/content/final_disease_dataset_complete.csv')\n",
        "\n",
        "# 2. Enhanced Data Cleaning\n",
        "def clean_medical_data(df):\n",
        "    # Handle missing values\n",
        "    df.fillna({\n",
        "        'Symptoms': '[]',\n",
        "        'Causes': '[]',\n",
        "        'Treatment': 'No treatment information available',\n",
        "        'Basic Precautions': 'No precautions specified',\n",
        "        'Additional Precautions': '',\n",
        "        'Diagnosis': 'Diagnosis method not specified',\n",
        "        'When to See a Doctor': 'Consult a doctor if symptoms persist'\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Convert string lists to actual lists\n",
        "    def safe_convert(x):\n",
        "        if isinstance(x, str) and x.startswith('['):\n",
        "            try:\n",
        "                return literal_eval(x)\n",
        "            except:\n",
        "                return [x.strip() for x in x.split(',')]\n",
        "        return [x] if pd.notna(x) else []\n",
        "\n",
        "    df['Symptoms'] = df['Symptoms'].apply(safe_convert)\n",
        "    df['Causes'] = df['Causes'].apply(safe_convert)\n",
        "\n",
        "    # Clean text fields\n",
        "    text_cols = ['Treatment', 'Basic Precautions', 'Additional Precautions',\n",
        "                 'Diagnosis', 'When to See a Doctor']\n",
        "    for col in text_cols:\n",
        "        df[col] = df[col].str.strip()\n",
        "\n",
        "    return df\n",
        "\n",
        "df = clean_medical_data(df)\n",
        "\n",
        "# 3. Verify the cleaned data\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(\"\\nSample data:\")\n",
        "print(df.head(3))\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 4. Create a more robust version of the diagnosis system\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import numpy as np\n",
        "\n",
        "class MedicalDiagnosisSystem:\n",
        "    def __init__(self, data):\n",
        "        self.df = data\n",
        "        self.embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "        self._prepare_system()\n",
        "\n",
        "    def _prepare_system(self):\n",
        "        # Create combined text for each disease\n",
        "        self.df['combined_info'] = self.df.apply(\n",
        "            lambda row: self._create_combined_info(row), axis=1)\n",
        "\n",
        "        # Generate embeddings\n",
        "        self.embeddings = self.embedder.encode(self.df['combined_info'].tolist())\n",
        "\n",
        "        # Build nearest neighbors model\n",
        "        self.nn = NearestNeighbors(n_neighbors=3, metric='cosine')\n",
        "        self.nn.fit(self.embeddings)\n",
        "\n",
        "    def _create_combined_info(self, row):\n",
        "        symptoms = ', '.join(row['Symptoms']) if isinstance(row['Symptoms'], list) else row['Symptoms']\n",
        "        causes = ', '.join(row['Causes']) if isinstance(row['Causes'], list) else row['Causes']\n",
        "        return (\n",
        "            f\"Disease: {row['Disease']}. Symptoms: {symptoms}. Causes: {causes}. \"\n",
        "            f\"Treatment: {row['Treatment']}. Precautions: {row['Basic Precautions']}. \"\n",
        "            f\"Diagnosis: {row['Diagnosis']}. When to see doctor: {row['When to See a Doctor']}\"\n",
        "        )\n",
        "\n",
        "    def diagnose(self, symptoms, top_n=3):\n",
        "        # Embed the input symptoms\n",
        "        symptom_embedding = self.embedder.encode([symptoms])\n",
        "\n",
        "        # Find nearest matches\n",
        "        distances, indices = self.nn.kneighbors(symptom_embedding, n_neighbors=top_n)\n",
        "\n",
        "        # Prepare results\n",
        "        results = []\n",
        "        for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n",
        "            disease_info = self.df.iloc[idx]\n",
        "            results.append({\n",
        "                'rank': i+1,\n",
        "                'disease': disease_info['Disease'],\n",
        "                'confidence': float(1 - dist),\n",
        "                'symptoms': disease_info['Symptoms'],\n",
        "                'causes': disease_info['Causes'],\n",
        "                'treatment': disease_info['Treatment'],\n",
        "                'precautions': disease_info['Basic Precautions'],\n",
        "                'additional_precautions': disease_info['Additional Precautions'],\n",
        "                'diagnosis_methods': disease_info['Diagnosis'],\n",
        "                'when_to_see_doctor': disease_info['When to See a Doctor']\n",
        "            })\n",
        "\n",
        "        return results\n",
        "\n",
        "# Initialize the system\n",
        "diagnosis_system = MedicalDiagnosisSystem(df)\n",
        "\n",
        "# 5. Example Usage\n",
        "def interactive_diagnosis():\n",
        "    print(\"Medical Diagnosis Assistant\")\n",
        "    print(\"Enter your symptoms (e.g., 'headache, fever'):\")\n",
        "    symptoms = input(\"> \")\n",
        "\n",
        "    results = diagnosis_system.diagnose(symptoms)\n",
        "\n",
        "    print(\"\\nTop Possible Diagnoses:\")\n",
        "    for result in results:\n",
        "        print(f\"\\n{result['rank']}. {result['disease']} (Confidence: {result['confidence']:.2f})\")\n",
        "        print(f\"   Symptoms: {', '.join(result['symptoms']) if isinstance(result['symptoms'], list) else result['symptoms']}\")\n",
        "        print(f\"   Possible Causes: {', '.join(result['causes']) if isinstance(result['causes'], list) else result['causes']}\")\n",
        "        print(f\"\\n   Treatment: {result['treatment']}\")\n",
        "        print(f\"\\n   Precautions: {result['precautions']}\")\n",
        "        if result['additional_precautions']:\n",
        "            print(f\"   Additional Precautions: {result['additional_precautions']}\")\n",
        "        print(f\"\\n   Diagnosis Methods: {result['diagnosis_methods']}\")\n",
        "        print(f\"\\n   When to See a Doctor: {result['when_to_see_doctor']}\")\n",
        "\n",
        "    print(\"\\nNote: This is for informational purposes only. Please consult a healthcare professional for proper diagnosis.\")\n",
        "\n",
        "# Run the interactive diagnosis\n",
        "interactive_diagnosis()"
      ],
      "metadata": {
        "id": "4VBE6k62pQVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NEW"
      ],
      "metadata": {
        "id": "9K6J-SeFklaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Robust Data Loading and Cleaning"
      ],
      "metadata": {
        "id": "J4XAQEnYkr0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "import re\n",
        "\n",
        "def load_and_clean_data(filepath):\n",
        "    # Load data with flexible parsing\n",
        "    try:\n",
        "        df = pd.read_csv(filepath, on_bad_lines='skip', engine='python')\n",
        "        print(f\"Initial load: {len(df)} rows\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Clean column names\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    # Handle missing values\n",
        "    df.replace('nan', np.nan, inplace=True)\n",
        "    df.fillna({\n",
        "        'Symptoms': '[]',\n",
        "        'Causes': '[]',\n",
        "        'Treatment': 'No treatment information available',\n",
        "        'Basic Precautions': 'No precautions specified',\n",
        "        'Additional Precautions': '',\n",
        "        'Diagnosis': 'Diagnosis method not specified',\n",
        "        'When to See a Doctor': 'Consult a doctor if symptoms persist'\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Improved list conversion\n",
        "    def safe_convert_to_list(x):\n",
        "        if isinstance(x, str):\n",
        "            try:\n",
        "                # Handle malformed lists\n",
        "                if x.startswith('[') and x.endswith(']'):\n",
        "                    return literal_eval(x)\n",
        "                # Handle pipe or comma separated values\n",
        "                if '|' in x:\n",
        "                    return [item.strip() for item in x.split('|') if item.strip()]\n",
        "                if ',' in x:\n",
        "                    return [item.strip() for item in x.split(',') if item.strip()]\n",
        "                return [x.strip()]\n",
        "            except:\n",
        "                return [x.strip()]\n",
        "        return [x] if pd.notna(x) else []\n",
        "\n",
        "    df['Symptoms'] = df['Symptoms'].apply(safe_convert_to_list)\n",
        "    df['Causes'] = df['Causes'].apply(safe_convert_to_list)\n",
        "\n",
        "    # Clean text fields\n",
        "    text_cols = ['Treatment', 'Basic Precautions', 'Additional Precautions',\n",
        "                 'Diagnosis', 'When to See a Doctor']\n",
        "    for col in text_cols:\n",
        "        df[col] = df[col].apply(lambda x: re.sub(r'\\s+', ' ', str(x))).str.strip()\n",
        "\n",
        "    # Remove duplicates\n",
        "    df.drop_duplicates(subset=['Disease'], keep='first', inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    print(f\"Final cleaned dataset: {len(df)} rows\")\n",
        "    return df\n",
        "\n",
        "# Load your dataset\n",
        "df = load_and_clean_data('/content/final_disease_dataset_complete.csv')"
      ],
      "metadata": {
        "id": "PjYok5VzklAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enhanced Diagnosis System"
      ],
      "metadata": {
        "id": "3__rjqpck1m_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "class AdvancedMedicalDiagnosisSystem:\n",
        "    def __init__(self, data):\n",
        "        self.df = data\n",
        "        self._prepare_models()\n",
        "\n",
        "    def _prepare_models(self):\n",
        "        # Create symptom strings for each disease\n",
        "        self.df['symptom_text'] = self.df['Symptoms'].apply(\n",
        "            lambda x: ', '.join(x) if isinstance(x, list) else str(x))\n",
        "\n",
        "        # Initialize embedding model\n",
        "        self.embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Create both TF-IDF and dense embeddings\n",
        "        self.tfidf = TfidfVectorizer(max_features=1000)\n",
        "        self.tfidf_vectors = self.tfidf.fit_transform(self.df['symptom_text'])\n",
        "\n",
        "        self.dense_vectors = self.embedder.encode(self.df['symptom_text'].tolist())\n",
        "\n",
        "        # Build hybrid similarity model\n",
        "        self.nn_model = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
        "        self.nn_model.fit(self.dense_vectors)\n",
        "\n",
        "    def _get_disease_info(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        return {\n",
        "            'disease': row['Disease'],\n",
        "            'symptoms': row['Symptoms'],\n",
        "            'causes': row['Causes'],\n",
        "            'treatment': row['Treatment'],\n",
        "            'precautions': row['Basic Precautions'],\n",
        "            'additional_precautions': row['Additional Precautions'],\n",
        "            'diagnosis_methods': row['Diagnosis'],\n",
        "            'when_to_see_doctor': row['When to See a Doctor']\n",
        "        }\n",
        "\n",
        "    def diagnose(self, symptoms, top_k=5):\n",
        "        # Generate both types of embeddings\n",
        "        dense_embedding = self.embedder.encode([symptoms])\n",
        "        tfidf_embedding = self.tfidf.transform([symptoms])\n",
        "\n",
        "        # Find similar diseases using dense embeddings\n",
        "        distances, indices = self.nn_model.kneighbors(dense_embedding, n_neighbors=top_k)\n",
        "\n",
        "        # Prepare results with combined confidence scores\n",
        "        results = []\n",
        "        for dist, idx in zip(distances[0], indices[0]):\n",
        "            disease_info = self._get_disease_info(idx)\n",
        "\n",
        "            # Calculate TF-IDF similarity for the top matches\n",
        "            tfidf_sim = np.dot(tfidf_embedding, self.tfidf_vectors[idx].T).toarray()[0][0]\n",
        "\n",
        "            # Combined confidence score\n",
        "            confidence = (0.7 * (1 - dist) + 0.3 * tfidf_sim)\n",
        "\n",
        "            results.append({\n",
        "                **disease_info,\n",
        "                'confidence': float(confidence)\n",
        "            })\n",
        "\n",
        "        # Sort by confidence\n",
        "        results.sort(key=lambda x: x['confidence'], reverse=True)\n",
        "\n",
        "        return results\n",
        "\n",
        "# Initialize the system\n",
        "diagnosis_system = AdvancedMedicalDiagnosisSystem(df)"
      ],
      "metadata": {
        "id": "-Qz3Hp9Wkuky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Improved User Interface"
      ],
      "metadata": {
        "id": "EzF-NN-1nDk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_diagnosis_output(results):\n",
        "    output = []\n",
        "    for i, result in enumerate(results, 1):\n",
        "        disease_entry = {\n",
        "            'rank': i,\n",
        "            'disease': result['disease'],\n",
        "            'confidence': f\"{result['confidence']:.2f}\",\n",
        "            'details': {\n",
        "                'Symptoms': ', '.join(result['symptoms']) if isinstance(result['symptoms'], list) else result['symptoms'],\n",
        "                'Possible Causes': ', '.join(result['causes']) if isinstance(result['causes'], list) else result['causes'],\n",
        "                'Treatment': result['treatment'],\n",
        "                'Precautions': result['precautions'],\n",
        "                'Additional Precautions': result['additional_precautions'] if result['additional_precautions'] else 'None',\n",
        "                'Diagnosis Methods': result['diagnosis_methods'],\n",
        "                'When to See a Doctor': result['when_to_see_doctor']\n",
        "            }\n",
        "        }\n",
        "        output.append(disease_entry)\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "uNprV52vk39t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def interactive_diagnosis():\n",
        "    print(\"\\n=== Medical Diagnosis Assistant ===\")\n",
        "    print(\"Enter your symptoms (e.g., 'fever, headache, cough'):\")\n",
        "    symptoms = input(\"> \").strip()\n",
        "\n",
        "    if not symptoms:\n",
        "        print(\"Please enter at least one symptom.\")\n",
        "        return\n",
        "\n",
        "    results = diagnosis_system.diagnose(symptoms)\n",
        "    formatted_results = format_diagnosis_output(results)\n",
        "\n",
        "    print(\"\\nüìù Input Symptoms:\")\n",
        "    print(f\"{symptoms}\\n\")\n",
        "\n",
        "    print(\"\\nTop Possible Diagnoses:\")\n",
        "    for result in formatted_results:\n",
        "        print(f\"\\n{result['rank']}. {result['disease']} (Confidence: {result['confidence']})\")\n",
        "        for key, value in result['details'].items():\n",
        "            if value and str(value).lower() not in ['none', 'nan', 'not specified']:\n",
        "                print(f\"   {key}: {value}\")\n",
        "\n",
        "    print(\"\\nImportant Note: This tool provides informational suggestions only.\")\n",
        "    print(\"Always consult a healthcare professional for proper diagnosis and treatment.\")\n",
        "\n",
        "# Run the interactive diagnosis\n",
        "interactive_diagnosis()"
      ],
      "metadata": {
        "id": "Gcd2mOf5oBsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(diagnosis_system, 'healthqai_model.pkl')\n",
        "\n"
      ],
      "metadata": {
        "id": "W5s5d1WhqsWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R9cywy6ktwbY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}